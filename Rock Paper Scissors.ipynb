{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b2accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "local_zip = \"rps.zip\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
    "zip_ref.extractall(\"tmp/rps-train\")\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = \"rps-test-set.zip\"\n",
    "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
    "zip_ref.extractall(\"tmp/rps-test\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3069b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"tmp/rps-train/rps\"\n",
    "\n",
    "rock_dir = os.path.join(base_dir, \"rock\")\n",
    "paper_dir = os.path.join(base_dir, \"paper\")\n",
    "scissors_dir = os.path.join(base_dir, \"scissors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1da6058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3473475 (13.25 MB)\n",
      "Trainable params: 3473475 (13.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6821cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss =\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbfaa6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2520 images belonging to 3 classes.\n",
      "Found 372 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = \"tmp/rps-train/rps\"\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "valid_dir = \"tmp/rps-test/rps-test-set\"\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "valid_gen = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(150,150),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "067af8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.1285 - accuracy: 0.3397WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n",
      "20/20 [==============================] - 60s 3s/step - loss: 1.1285 - accuracy: 0.3397 - val_loss: 1.0639 - val_accuracy: 0.4597\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 48s 2s/step - loss: 1.3033 - accuracy: 0.4123\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 51s 3s/step - loss: 1.0057 - accuracy: 0.4766\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 63s 3s/step - loss: 0.9582 - accuracy: 0.5274\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 65s 3s/step - loss: 0.9134 - accuracy: 0.5694\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 66s 3s/step - loss: 0.7619 - accuracy: 0.6560\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 59s 3s/step - loss: 0.6785 - accuracy: 0.6750\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 60s 3s/step - loss: 0.5870 - accuracy: 0.7306\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 61s 3s/step - loss: 0.5114 - accuracy: 0.7742\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 62s 3s/step - loss: 0.4093 - accuracy: 0.8262\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 61s 3s/step - loss: 0.3575 - accuracy: 0.8540\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 62s 3s/step - loss: 0.3212 - accuracy: 0.8647\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 64s 3s/step - loss: 0.2919 - accuracy: 0.8829\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 69s 3s/step - loss: 0.2449 - accuracy: 0.9099\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 59s 3s/step - loss: 0.2555 - accuracy: 0.9024\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 60s 3s/step - loss: 0.1823 - accuracy: 0.9329\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.2577 - accuracy: 0.9067\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 61s 3s/step - loss: 0.1515 - accuracy: 0.9437\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 62s 3s/step - loss: 0.2262 - accuracy: 0.9159\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 58s 3s/step - loss: 0.0869 - accuracy: 0.9730\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 57s 3s/step - loss: 0.1759 - accuracy: 0.9353\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 58s 3s/step - loss: 0.1216 - accuracy: 0.9571\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 61s 3s/step - loss: 0.1222 - accuracy: 0.9571\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 75s 4s/step - loss: 0.0900 - accuracy: 0.9671\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 62s 3s/step - loss: 0.1054 - accuracy: 0.9611\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen,\n",
    "                   epochs=25,\n",
    "                   steps_per_epoch=20,\n",
    "                   validation_data = valid_gen,\n",
    "                   verbose=1,\n",
    "                   validation_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc89278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile.ZipFile(\"./rps-validation.zip\", \"r\").extractall(\"./rps-validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "652de726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "paper-hires1.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "paper-hires2.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "paper1.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "paper2.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "paper3.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "paper4.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "paper5.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "paper6.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "paper7.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "paper8.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "paper9.png\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "rock-hires1.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock-hires2.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "rock1.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "rock2.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "rock3.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "rock4.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "rock5.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "rock6.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock7.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "rock8.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "rock9.png\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "scissors-hires1.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "scissors-hires2.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "scissors1.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "scissors2.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "scissors3.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "scissors4.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "scissors5.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "scissors6.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "scissors7.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "scissors8.png\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "scissors9.png\n",
      "[[0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "val_pics = os.listdir(\"./rps-validation\")\n",
    "\n",
    "for pic in val_pics:\n",
    "    path = os.path.join(\"./rps-validation\", pic)\n",
    "    img = load_img(path, target_size=(150, 150))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(pic)\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac80c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
